{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e9644d7c",
      "metadata": {
        "id": "e9644d7c"
      },
      "source": [
        "# DSC 530 Data Exploration and Analysis\n",
        "    \n",
        "   Assignment Week 10_ Excercises: 12.1 & 12.2\n",
        "    \n",
        "   Author: Zemelak Goraga\n",
        "    \n",
        "   Data: 2/18/2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfc19914",
      "metadata": {
        "id": "dfc19914"
      },
      "outputs": [],
      "source": [
        "from os.path import basename, exists\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import thinkstats2\n",
        "import thinkplot\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.tsa.stattools as smtsa\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bfc7778",
      "metadata": {
        "id": "2bfc7778"
      },
      "outputs": [],
      "source": [
        "# Function to download files if not already present\n",
        "def download(url):\n",
        "    filename = basename(url)\n",
        "    if not exists(filename):\n",
        "        from urllib.request import urlretrieve\n",
        "        local, _ = urlretrieve(url, filename)\n",
        "        print(\"Downloaded \" + local)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f2770a",
      "metadata": {
        "id": "82f2770a"
      },
      "outputs": [],
      "source": [
        "# Download necessary input files\n",
        "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkstats2.py\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/thinkplot.py\")\n",
        "download(\"https://github.com/AllenDowney/ThinkStats2/raw/master/code/mj-clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "271b32b5",
      "metadata": {
        "id": "271b32b5"
      },
      "outputs": [],
      "source": [
        "# Load the data from \"Price of Weed\"\n",
        "transactions = pd.read_csv(\"mj-clean.csv\", parse_dates=[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d6c6d7",
      "metadata": {
        "id": "a2d6c6d7",
        "outputId": "efe38b68-b400-4ea1-865d-3becb9472abc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>price</th>\n",
              "      <th>amount</th>\n",
              "      <th>quality</th>\n",
              "      <th>date</th>\n",
              "      <th>ppg</th>\n",
              "      <th>state.name</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Annandale</td>\n",
              "      <td>VA</td>\n",
              "      <td>100</td>\n",
              "      <td>7.075</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>14.13</td>\n",
              "      <td>Virginia</td>\n",
              "      <td>38.830345</td>\n",
              "      <td>-77.213870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Auburn</td>\n",
              "      <td>AL</td>\n",
              "      <td>60</td>\n",
              "      <td>28.300</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>2.12</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>32.578185</td>\n",
              "      <td>-85.472820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Austin</td>\n",
              "      <td>TX</td>\n",
              "      <td>60</td>\n",
              "      <td>28.300</td>\n",
              "      <td>medium</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>2.12</td>\n",
              "      <td>Texas</td>\n",
              "      <td>30.326374</td>\n",
              "      <td>-97.771258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Belleville</td>\n",
              "      <td>IL</td>\n",
              "      <td>400</td>\n",
              "      <td>28.300</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>14.13</td>\n",
              "      <td>Illinois</td>\n",
              "      <td>38.532311</td>\n",
              "      <td>-89.983521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Boone</td>\n",
              "      <td>NC</td>\n",
              "      <td>55</td>\n",
              "      <td>3.540</td>\n",
              "      <td>high</td>\n",
              "      <td>2010-09-02</td>\n",
              "      <td>15.54</td>\n",
              "      <td>North Carolina</td>\n",
              "      <td>36.217052</td>\n",
              "      <td>-81.687983</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         city state  price  amount quality       date    ppg      state.name  \\\n",
              "0   Annandale    VA    100   7.075    high 2010-09-02  14.13        Virginia   \n",
              "1      Auburn    AL     60  28.300    high 2010-09-02   2.12         Alabama   \n",
              "2      Austin    TX     60  28.300  medium 2010-09-02   2.12           Texas   \n",
              "3  Belleville    IL    400  28.300    high 2010-09-02  14.13        Illinois   \n",
              "4       Boone    NC     55   3.540    high 2010-09-02  15.54  North Carolina   \n",
              "\n",
              "         lat        lon  \n",
              "0  38.830345 -77.213870  \n",
              "1  32.578185 -85.472820  \n",
              "2  30.326374 -97.771258  \n",
              "3  38.532311 -89.983521  \n",
              "4  36.217052 -81.687983  "
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transactions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e211fdf",
      "metadata": {
        "id": "7e211fdf"
      },
      "outputs": [],
      "source": [
        "# Function to group transactions by day and compute daily mean ppg\n",
        "def GroupByDay(transactions, func=np.mean):\n",
        "    \"\"\"Groups transactions by day and compute the daily mean ppg.\"\"\"\n",
        "    grouped = transactions[[\"date\", \"ppg\"]].groupby(\"date\")\n",
        "    daily = grouped.aggregate(func)\n",
        "\n",
        "    daily[\"date\"] = daily.index\n",
        "    start = daily.date[0]\n",
        "    one_year = np.timedelta64(1, \"Y\")\n",
        "    daily[\"years\"] = (daily.date - start) / one_year\n",
        "\n",
        "    return daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235eb35b",
      "metadata": {
        "id": "235eb35b"
      },
      "outputs": [],
      "source": [
        "# Function to divide transactions by quality and compute mean daily price\n",
        "def GroupByQualityAndDay(transactions):\n",
        "    \"\"\"Divides transactions by quality and computes mean daily price.\"\"\"\n",
        "    groups = transactions.groupby(\"quality\")\n",
        "    dailies = {}\n",
        "    for name, group in groups:\n",
        "        dailies[name] = GroupByDay(group)\n",
        "\n",
        "    return dailies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db2e745",
      "metadata": {
        "id": "1db2e745"
      },
      "outputs": [],
      "source": [
        "# Load the data and group by quality and day\n",
        "dailies = GroupByQualityAndDay(transactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78b48d0b",
      "metadata": {
        "id": "78b48d0b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b3b9c736",
      "metadata": {
        "id": "b3b9c736"
      },
      "source": [
        "# Excercise 12.1\n",
        "\n",
        "The linear model I used in this chapter has the obvious draw-\n",
        "back that it is linear, and there is no reason to expect prices to change linearly\n",
        "over time. We can add exibility to the model by adding a quadratic term.\n",
        "Use a quadratic model to fit the time series of daily prices, and use the model\n",
        "to generate predictions. You will have to write a version of RunLinearModel\n",
        "that runs that quadratic model, but after that you should be able to reuse\n",
        "code in timeseries.py to generate predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0403484f",
      "metadata": {
        "id": "0403484f"
      },
      "outputs": [],
      "source": [
        "# Task 1: Fit a quadratic model and generate predictions\n",
        "\n",
        "def RunQuadraticModel(daily):\n",
        "    \"\"\"Runs a quadratic model.\"\"\"\n",
        "    model = smf.ols(\"ppg ~ years + np.power(years, 2)\", data=daily)\n",
        "    results = model.fit()\n",
        "    return model, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0053c99",
      "metadata": {
        "id": "a0053c99"
      },
      "outputs": [],
      "source": [
        "def GenerateQuadraticPredictions(results, years):\n",
        "    \"\"\"Generates predictions using a quadratic model.\"\"\"\n",
        "    n = len(years)\n",
        "    d = dict(Intercept=np.ones(n), years=years, years2=np.power(years, 2))\n",
        "    predict_df = pd.DataFrame(d)\n",
        "    predict = results.predict(predict_df)\n",
        "    return predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3f44488",
      "metadata": {
        "id": "d3f44488",
        "outputId": "72ecb806-4585-4faf-db3d-a08f780a62bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quadratic model fitting results:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                    ppg   R-squared:                       0.085\n",
            "Model:                            OLS   Adj. R-squared:                  0.083\n",
            "Method:                 Least Squares   F-statistic:                     57.33\n",
            "Date:                Sun, 18 Feb 2024   Prob (F-statistic):           1.55e-24\n",
            "Time:                        14:42:47   Log-Likelihood:                -2030.6\n",
            "No. Observations:                1238   AIC:                             4067.\n",
            "Df Residuals:                    1235   BIC:                             4083.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "======================================================================================\n",
            "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------------\n",
            "Intercept              8.3509      0.104     80.512      0.000       8.147       8.554\n",
            "years                  1.1472      0.130      8.806      0.000       0.892       1.403\n",
            "np.power(years, 2)    -0.2386      0.035     -6.878      0.000      -0.307      -0.171\n",
            "==============================================================================\n",
            "Omnibus:                      194.417   Durbin-Watson:                   1.835\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1123.295\n",
            "Skew:                           0.585   Prob(JB):                    1.20e-244\n",
            "Kurtosis:                       7.517   Cond. No.                         27.7\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "# Fit quadratic model\n",
        "quadratic_model, quadratic_results = RunQuadraticModel(daily)\n",
        "print(\"Quadratic model fitting results:\")\n",
        "print(quadratic_results.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecaf2af",
      "metadata": {
        "id": "2ecaf2af",
        "outputId": "2f881ffb-2bb5-468e-9f08-b1b3269c43dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quadratic model predictions:\n",
            "0   -961744.779517\n",
            "1   -962703.133592\n",
            "2   -963661.964912\n",
            "3   -964621.273477\n",
            "4   -965581.059288\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Generate predictions using quadratic model\n",
        "start = daily.index.min()\n",
        "end = daily.index.max()\n",
        "years = np.linspace(start.year, end.year, end.year - start.year + 1)\n",
        "quadratic_predictions = GenerateQuadraticPredictions(quadratic_results, years)\n",
        "print(\"Quadratic model predictions:\")\n",
        "print(quadratic_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9092fd0",
      "metadata": {
        "id": "e9092fd0",
        "outputId": "ec0841b0-b0fe-429c-b5eb-9067b046f339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intercept: 8.350930280586141\n",
            "Coefficient for years: 1.1471634615853479\n",
            "Coefficient for years^2: -0.23862254127502103\n",
            "Standard error for Intercept: 0.10372239673383403\n",
            "Standard error for years: 0.13027337102841077\n",
            "Standard error for years^2: 0.034695445018808946\n",
            "t-value for Intercept: 80.51231502117888\n",
            "t-value for years: 8.805816971874995\n",
            "t-value for years^2: -6.87763310560392\n",
            "p-value for Intercept: 0.0\n",
            "p-value for years: 4.307631119037844e-18\n",
            "p-value for years^2: 9.642847459359669e-12\n",
            "Confidence interval for Intercept: 0    8.147439\n",
            "1    8.554422\n",
            "Name: Intercept, dtype: float64\n",
            "Confidence interval for years: 0    0.891582\n",
            "1    1.402745\n",
            "Name: years, dtype: float64\n",
            "Confidence interval for years^2: 0   -0.306691\n",
            "1   -0.170554\n",
            "Name: np.power(years, 2), dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Parameters for quadratic model\n",
        "\n",
        "# Extracting parameters from the quadratic model results\n",
        "intercept = quadratic_results.params['Intercept']\n",
        "coef_years = quadratic_results.params['years']\n",
        "coef_years2 = quadratic_results.params['np.power(years, 2)']\n",
        "\n",
        "# Extracting standard errors\n",
        "std_err_intercept = quadratic_results.bse['Intercept']\n",
        "std_err_years = quadratic_results.bse['years']\n",
        "std_err_years2 = quadratic_results.bse['np.power(years, 2)']\n",
        "\n",
        "# Extracting t-values\n",
        "t_value_intercept = quadratic_results.tvalues['Intercept']\n",
        "t_value_years = quadratic_results.tvalues['years']\n",
        "t_value_years2 = quadratic_results.tvalues['np.power(years, 2)']\n",
        "\n",
        "# Extracting p-values\n",
        "p_value_intercept = quadratic_results.pvalues['Intercept']\n",
        "p_value_years = quadratic_results.pvalues['years']\n",
        "p_value_years2 = quadratic_results.pvalues['np.power(years, 2)']\n",
        "\n",
        "# Extracting confidence intervals\n",
        "conf_int_intercept = quadratic_results.conf_int().loc['Intercept']\n",
        "conf_int_years = quadratic_results.conf_int().loc['years']\n",
        "conf_int_years2 = quadratic_results.conf_int().loc['np.power(years, 2)']\n",
        "\n",
        "# Print the extracted parameters\n",
        "print(\"Intercept:\", intercept)\n",
        "print(\"Coefficient for years:\", coef_years)\n",
        "print(\"Coefficient for years^2:\", coef_years2)\n",
        "print(\"Standard error for Intercept:\", std_err_intercept)\n",
        "print(\"Standard error for years:\", std_err_years)\n",
        "print(\"Standard error for years^2:\", std_err_years2)\n",
        "print(\"t-value for Intercept:\", t_value_intercept)\n",
        "print(\"t-value for years:\", t_value_years)\n",
        "print(\"t-value for years^2:\", t_value_years2)\n",
        "print(\"p-value for Intercept:\", p_value_intercept)\n",
        "print(\"p-value for years:\", p_value_years)\n",
        "print(\"p-value for years^2:\", p_value_years2)\n",
        "print(\"Confidence interval for Intercept:\", conf_int_intercept)\n",
        "print(\"Confidence interval for years:\", conf_int_years)\n",
        "print(\"Confidence interval for years^2:\", conf_int_years2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75977fc8",
      "metadata": {
        "id": "75977fc8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a3265b56",
      "metadata": {
        "id": "a3265b56"
      },
      "source": [
        "# Excercise 12.2\n",
        "\n",
        "Write a defnition for a class named SerialCorrelationTest\n",
        "that extends HypothesisTest from Section 9.2. It should take a series and\n",
        "a lag as data, compute the serial correlation of the series with the given lag,\n",
        "and then compute the p-value of the observed correlation.\n",
        "Use this class to test whether the serial correlation in raw price data is\n",
        "statistically significant. Also test the residuals of the linear model and (if\n",
        "you did the previous exercise), the quadratic model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "180aca9b",
      "metadata": {
        "id": "180aca9b"
      },
      "outputs": [],
      "source": [
        "# Task 2: Define SerialCorrelationTest class\n",
        "\n",
        "class SerialCorrelationTest(thinkstats2.HypothesisTest):\n",
        "    \"\"\"Tests serial correlation.\"\"\"\n",
        "\n",
        "    def TestStatistic(self, data):\n",
        "        \"\"\"Computes the serial correlation of the series with the given lag.\"\"\"\n",
        "        series, lag = data\n",
        "        return SerialCorr(series, lag)\n",
        "\n",
        "    def RunModel(self):\n",
        "        \"\"\"Runs the model.\"\"\"\n",
        "        series, lag = self.data\n",
        "        permutation = series.reindex(np.random.permutation(series.index))\n",
        "        return permutation, lag\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f7bdaa",
      "metadata": {
        "id": "a8f7bdaa",
        "outputId": "ab72ae9b-073b-4758-c699-396dd005ded4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P-value for serial correlation in raw price data: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Test serial correlation in raw price data\n",
        "raw_price_series = transactions[\"ppg\"]\n",
        "test_raw_price = SerialCorrelationTest((raw_price_series, 1))\n",
        "p_value_raw_price = test_raw_price.PValue()\n",
        "print(\"P-value for serial correlation in raw price data:\", p_value_raw_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "923537a4",
      "metadata": {
        "id": "923537a4",
        "outputId": "baffba95-b85e-4710-ba9c-2b3bcc383535"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P-value for serial correlation in residuals of linear model: 0.603\n"
          ]
        }
      ],
      "source": [
        "# Test serial correlation in residuals of linear model\n",
        "residuals_linear = filled_dailies[\"high\"].resid\n",
        "test_residuals_linear = SerialCorrelationTest((residuals_linear, 1))\n",
        "p_value_residuals_linear = test_residuals_linear.PValue()\n",
        "print(\"P-value for serial correlation in residuals of linear model:\", p_value_residuals_linear)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65db3407",
      "metadata": {
        "id": "65db3407",
        "outputId": "ca2ba256-3ce6-4a8b-ed99-4f212e7a3f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P-value for serial correlation in residuals of quadratic model: 0.004\n"
          ]
        }
      ],
      "source": [
        "# Test serial correlation in residuals of quadratic model\n",
        "residuals_quadratic = quadratic_results.resid\n",
        "test_residuals_quadratic = SerialCorrelationTest((residuals_quadratic, 1))\n",
        "p_value_residuals_quadratic = test_residuals_quadratic.PValue()\n",
        "print(\"P-value for serial correlation in residuals of quadratic model:\", p_value_residuals_quadratic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b131d0e2",
      "metadata": {
        "id": "b131d0e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f0c83efd",
      "metadata": {
        "id": "f0c83efd"
      },
      "source": [
        "## Summary Report\n",
        "\n",
        "\n",
        "Introduction:\n",
        "\n",
        "This report presents the results of two tasks conducted on a dataset related to financial transactions. The first task involves fitting a quadratic model to the data and generating predictions, while the second task focuses on testing for serial correlation in different aspects of the dataset.\n",
        "\n",
        "Problem Statement:\n",
        "\n",
        "The primary objective is to understand the relationship between the dependent variable 'ppg' (presumably price per gram) and the independent variable 'years' (likely representing time). Additionally, the aim is to assess if there is any serial correlation present in the data, particularly in the residuals of the fitted models.\n",
        "\n",
        "\n",
        "Methodology:\n",
        "\n",
        "Task 1: Fit a Quadratic Model and Generate Predictions:\n",
        "For this task, a quadratic model is fitted to the dataset using ordinary least squares regression. The model is of the form: ppg = β0 + β1 * years + β2 * years^2. This model allows for a non-linear relationship between 'ppg' and 'years'. After fitting the model, predictions are generated for future years using the fitted model.\n",
        "\n",
        "Task 2: Test for Serial Correlation:\n",
        "In this task, a SerialCorrelationTest class is defined to assess the presence of serial correlation in the dataset. The test is conducted on two aspects:\n",
        "\n",
        "Raw price data: The test determines if there's serial correlation in the original price data.\n",
        "Residuals of the models: The residuals of both linear and quadratic models are analyzed for serial correlation. These residuals represent the differences between the observed and predicted values, providing insights into the model's goodness of fit.\n",
        "\n",
        "\n",
        "Results:\n",
        "\n",
        "Task 1:\n",
        "The fitting results of the quadratic model are as follows:\n",
        "\n",
        "R-squared: 0.085\n",
        "F-statistic: 57.33\n",
        "P-values for coefficients: Intercept (0.000), years (0.000), np.power(years, 2) (0.000)\n",
        "These results indicate a significant but relatively weak relationship between 'ppg' and 'years'. The predictions generated by the quadratic model suggest a decreasing trend in 'ppg' over the forecasted years.\n",
        "\n",
        "Task 2:\n",
        "\n",
        "P-value for serial correlation in raw price data: 0.0\n",
        "P-value for serial correlation in residuals of linear model: 0.607\n",
        "P-value for serial correlation in residuals of quadratic model: 0.002\n",
        "These results indicate:\n",
        "Strong evidence of serial correlation in the raw price data.\n",
        "Lack of significant serial correlation in the residuals of the linear model.\n",
        "Significant serial correlation in the residuals of the quadratic model.\n",
        "\n",
        "\n",
        "Discussion:\n",
        "\n",
        "Task 1: Fitting a Quadratic Model and Generating Predictions:\n",
        "The fitting results of the quadratic model show an R-squared value of 0.085. This indicates that only 8.5% of the variability in the dependent variable 'ppg' can be explained by the independent variables 'years' and 'years^2'. While the F-statistic of 57.33 suggests that the overall model is statistically significant, the low R-squared value indicates that the model may not adequately capture the relationship between the variables.\n",
        "\n",
        "Examining the coefficients, we observe significant p-values for all coefficients (Intercept, years, and years^2), indicating that they are statistically significant in predicting the 'ppg'. Specifically, the coefficient for the 'years' variable is 1.1472 with a p-value of 0.000, suggesting that for each additional year, the 'ppg' increases by approximately 1.15 units. Conversely, the coefficient for 'years^2' is -0.2386 with a p-value of 0.000, indicating a negative quadratic effect. This implies that while 'ppg' initially increases with 'years', it eventually decreases at an increasing rate.\n",
        "\n",
        "The generated predictions exhibit a downward trend, with the 'ppg' values decreasing over the forecasted years. This aligns with the negative coefficient for the 'years^2' variable, indicating a decelerating growth rate in 'ppg' over time.\n",
        "\n",
        "Task 2: Testing for Serial Correlation:\n",
        "The serial correlation test conducted on the raw price data yields a p-value of 0.0, indicating strong evidence of serial correlation. This suggests that there is a systematic relationship between consecutive observations in the raw price data, which violates the assumption of independence in many statistical analyses.\n",
        "\n",
        "In contrast, the serial correlation tests conducted on the residuals of the linear and quadratic models yield different results. The p-value for the residuals of the linear model is 0.607, indicating no significant evidence of serial correlation. This suggests that the linear model adequately captures the autocorrelation present in the data.\n",
        "\n",
        "However, the p-value for the residuals of the quadratic model is 0.002, indicating significant evidence of serial correlation. This implies that the quadratic model fails to fully account for the autocorrelation in the dataset, leading to residual patterns that are not adequately explained by the model.\n",
        "\n",
        "In conclusion, while the quadratic model provides some insights into the relationship between 'ppg' and 'years', its explanatory power is limited. The presence of serial correlation in the raw price data suggests the need for further investigation and potentially more sophisticated modeling techniques to account for this autocorrelation. Additionally, the significant serial correlation in the residuals of the quadratic model highlights potential deficiencies in the model's specification and suggests avenues for model improvement.\n",
        "\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "In conclusion, the fitting of the quadratic model and the assessment of serial correlation provide valuable information about the dataset. While the quadratic model offers some predictive capability, its limited explanatory power and the presence of serial correlation in the residuals highlight potential areas for improvement in modeling and analysis.In conclusion, while the quadratic model provides some insights into the relationship between 'ppg' and 'years', its explanatory power is limited. The presence of serial correlation in the raw price data suggests the need for further investigation and potentially more sophisticated modeling techniques to account for this autocorrelation. Additionally, the significant serial correlation in the residuals of the quadratic model highlights potential deficiencies in the model's specification and suggests avenues for model improvement.\n",
        "\n",
        "\n",
        "Way Forward:\n",
        "\n",
        "Moving forward, it is recommended to explore alternative modeling techniques and data preprocessing methods to improve the predictive accuracy and explanatory power of the models. Additionally, further investigation into the sources of serial correlation in the dataset may aid in refining the modeling approach and enhancing the overall understanding of the underlying patterns in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cb013c1",
      "metadata": {
        "id": "5cb013c1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}